{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = ['BKK','Chiangmai','Khonkaen','Rayong','Saraburi','Surat']\n",
    "province = provinces[3]\n",
    "data = pd.read_csv('./'+province+'/train/'+province.lower()+'_train_format_2.csv')\n",
    "\n",
    "y_train = data.pop('PM2.5')\n",
    "X_train = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791fb0334eff414998d23e50ec0812c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f82b4e596d4bcc80b7cdaf2d64b35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118f74619f0f4260953381474a172da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cc24e5d55a4ef09db08a2626258fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "i = 1\n",
    "score = []\n",
    "for tr_index, val_index in tqdm_notebook(tscv.split(X_train)):\n",
    "    X_tr, X_val = X_train.iloc[tr_index], X_train.iloc[val_index]\n",
    "    y_tr, y_val = y_train.iloc[tr_index], y_train.iloc[val_index]\n",
    "    for mf in tqdm_notebook(np.linspace(1, 7, 7)):\n",
    "        for ne in np.linspace(50, 100, 6):\n",
    "            for md in np.linspace(20, 40, 5):\n",
    "                for msl in np.linspace(30, 100, 8):\n",
    "                    rfr = RandomForestRegressor(\n",
    "                        max_features=int(mf),\n",
    "                        n_estimators=int(ne),\n",
    "                        max_depth=int(md),\n",
    "                        min_samples_leaf=int(msl),\n",
    "                        n_jobs = -1)\n",
    "                    rfr.fit(X_tr, y_tr)\n",
    "                    y_pred = rfr.predict(X_val)\n",
    "                    score.append([i,\n",
    "                                  mf, \n",
    "                                  ne,\n",
    "                                  md, \n",
    "                                  msl, \n",
    "                                  rfr.score(X_val, y_val),\n",
    "                                  np.sqrt(metrics.mean_squared_error(y_val, y_pred))])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('rf_'+province.lower()+'_score.pickle', 'wb') as fp:\n",
    "    pickle.dump(score, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parem: [1, 2.0, 50.0, 30.0, 40.0, -0.8194841886020148, 9.29520811161377]\n"
     ]
    }
   ],
   "source": [
    "score2 = np.array(score)\n",
    "print('best parem:',score[np.argmin(score2, axis=0)[-1]]) #please note all these params in note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'BKK':[7.0, 70.0, 40.0, 100.0],'Chiangmai':[7.0, 50.0, 40.0, 100.0],'Khonkaen':[1.0, 70.0, 30.0, 90.0],'Rayong':[2.0, 50.0, 30.0, 40.0],'Saraburi':[3.0, 50.0, 20.0, 90.0],'Surat':[2.0, 60.0, 20.0, 30.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "province = 'BKK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./'+province+'/train/'+province.lower()+'_train_format_2.csv')\n",
    "# train_data.head()\n",
    "\n",
    "y_train = train_data.pop('PM2.5')\n",
    "X_train = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(province+'_clean.csv')\n",
    "test_data['date_time'] = pd.to_datetime(test_data['date_time'])\n",
    "test_data['year'] = test_data['date_time'].dt.year\n",
    "test_data['month'] = test_data['date_time'].dt.month\n",
    "test_data['day'] = test_data['date_time'].dt.day\n",
    "test_data['hour'] = test_data['date_time'].dt.hour\n",
    "test_data = test_data[['year','month','day','hour','temp','wind speed','wind dir','PM2.5']]\n",
    "test_data.dropna(inplace=True)\n",
    "# test_data.head()\n",
    "y_test = test_data.pop('PM2.5')\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.575646339818894\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(\n",
    "                        max_features=int(param_dict[province][0]),\n",
    "                        n_estimators=int(param_dict[province][1]),\n",
    "                        max_depth=int(param_dict[province][2]),\n",
    "                        min_samples_leaf=int(param_dict[province][3]),\n",
    "                        n_jobs = -1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of BKK: 10.531763558991464\n",
      "RMSE of Chiangmai: 21.129193184149443\n",
      "RMSE of Khonkaen: 12.697137874589506\n",
      "RMSE of Rayong: 9.225255646244463\n",
      "RMSE of Saraburi: 15.02105761057381\n",
      "RMSE of Surat: 7.430652517725827\n",
      "all province RMSE: 13.418868100953738\n"
     ]
    }
   ],
   "source": [
    "SE = []\n",
    "n = 0\n",
    "for province in param_dict:\n",
    "    train_data = pd.read_csv('./'+province+'/train/'+province.lower()+'_train_format_2.csv')\n",
    "    y_train = train_data.pop('PM2.5')\n",
    "    X_train = train_data\n",
    "    test_data = pd.read_csv(province+'_clean.csv')\n",
    "    test_data['date_time'] = pd.to_datetime(test_data['date_time'])\n",
    "    test_data['year'] = test_data['date_time'].dt.year\n",
    "    test_data['month'] = test_data['date_time'].dt.month\n",
    "    test_data['day'] = test_data['date_time'].dt.day\n",
    "    test_data['hour'] = test_data['date_time'].dt.hour\n",
    "    test_data = test_data[['year','month','day','hour','temp','wind speed','wind dir','PM2.5']]\n",
    "    test_data.dropna(inplace=True)\n",
    "    y_test = test_data.pop('PM2.5')\n",
    "    X_test = test_data\n",
    "    rfr = RandomForestRegressor(\n",
    "                        max_features=int(param_dict[province][0]),\n",
    "                        n_estimators=int(param_dict[province][1]),\n",
    "                        max_depth=int(param_dict[province][2]),\n",
    "                        min_samples_leaf=int(param_dict[province][3]),\n",
    "                        n_jobs = -1)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    y_pred = rfr.predict(X_test)\n",
    "    SE.append(np.sum(np.square(np.subtract(np.array(y_test), np.array(y_pred)))))\n",
    "    n += len(y_pred)\n",
    "    print('RMSE of '+province+':',np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('all province RMSE:',np.sqrt(np.sum(np.array(SE))/n))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "723dc80cb05396c6d0019b793cc9629de1a15570232a2a29e62999a170644e05"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
